---
title: >
  Switching to a WebAssembly Runtime
pubDate: 2025-08-25
intro: Going forward TrailBase will rely on a WebAssembly rather than a V8 JavaScript runtime.
tags: ["WASM"]
author: sebastian
image: ./_wasm_logo.svg
---

import { RuntimeFib40Times } from "./_switching_to_a_wasm_runtime.tsx";

<div class="flex justify-center">
  <div class="h-[400px] w-[90%]">
    <RuntimeFib40Times client:only="solid-js" />
  </div>
</div>

TrailBase has been embedding a V8 JavaScript runtime for the last 10 months
allowing users to implement custom HTTP and job handlers.
During this time we've experienced several issues and limitations - we're
therefore excited to announce that TrailBase is adopting the
[wasmtime](https://github.com/bytecodealliance/wasmtime) WebAssembly (WASM)
runtime.

This is TrailBase biggest user-facing change, and likely will be for a long time.
To ease migration, the plan for releases v0.17 and v0.it 18 to be transitional,
i.e. support both runtimes.
First, v0.17 will make the new WASM runtime available, we'll collect early
feedback, address issues and stabilize the guest APIs.
The v0.18 release will then mark the point when users will need to migrate. If
everything goes to plan, subsequent releases will remove V8.

In the following article we're going to explain the rational, the opportunities
and what to watch out for.

## Rational

Before getting into the benefits of the new runtime, let's quickly touch on some
of the issues we had with the previous one.

The V8 JavaScript runtime is a amazing piece of engineering.
However, it was never designed as an embeddable or backend-first solution.
It's primary target remains browsers.
Third-party vendors like Node.js and Deno have taken it upon themselves to
extend V8, with APIs for accessing the file-system, sockets, etc.
These extensions themselves are extensive and have sprawling dependencies.
They're also primarily designed to serve their own ecosystem rather than be
embedded elsewhere.
For reference, the JS runtime makes up two thirds of TrailBase binary, even
though only a subset of APIs are linked.
Tis is a big chunk of unsafe code - despite well written - receiving particular
scrutiny due to its critical nature.

{/* Running stale versions poses an elevated security risk. */}

{/*
Ultimately, it has become a game of whack-a-mole, while at the same time not
even providing a fully Node.js compatible environment.
*/}

In practice, the current JS runtime isn't serving anyone particularly well:

* it's not Node.js compatible,
* it inflates binary size and the security surface,
* newer deno versions bundle a stale SQLite causing linker issues, and
* prevents us from building "truly" static binaries with MUSL[^1].

The new WASM runtime, on the other hand, is a lot simpler, safer and yet
high-performant. It also supports WASI[^2], which greatly eases embedding and
allows us to support guests in multiple languages.

## Opportunities

### Rigorous State Isolation & Performance

V8's isolates and JIT are expensive, they thus typically re-used across
requests, opening up the gatas for accidental state sharing. There are
specialized JIT-free runtimes like [LLRT](https://github.com/awslabs/llrt) to
specifically solve this issue at the expense of performance.
Our WASM runtime, on the other hand, makes it cheap and easy to spawn fully isolated
instances per request[^4].
Combined with efficient guest environments it can even outperform V8 by a factor of ~4.

### Flexible Guest Language Choice

Many languages support compilation to WASM. This gives users more freedom in
choosing and customizing their server-side environment.
For now, TrailBase supports JS/TS and Rust, but we're planning to support
[more](https://github.com/bytecodealliance/wasmtime/blob/main/README.md#language-support)
in the future.

Moreover, different endpoints can be implemented in different WASM components
and thus different languages, allowing you to optimize performance as you go.
For example, an expensive, high-QPS endpoint could be rewritten in Rust
yielding 10x-100x performance gains.

### Better I/O Sandboxing

Previously, isolates were given untethered I/O access, which together with a
very dynamic guest language can be a security risk.
We now limit I/O to read-only file access at an explicitly provided sandbox root.
We're planning ot extend I/O capabilities over time on a per-need basis.
If you're missing anything, let us know.

The new integration also fixes timers - such as `setTimeout` and `setInterval`, which
were unreliable in our previous V8 integration.

### Less Code

As mentioned before, switching off V8 removes a lot of high-scrunity code, cuts
binary size roughly in half and lets us build truly static binaries with MUSL.

### Rethinking Composition & Licensing Model

The increased flexibility and performance provided by the new WASM runtime
opens up a path to making this a singular entry-point for extending TrailBase
(including SQLite extensions) as opposed to framework use-caess.
In turn, this may allow us to adopt a more popular copyleft license w/o
inflicting obligations on your business-logic.

{/*

* No accidental state sharing![^4]
* Many more languages can be supported: C#, Python, Go, Dart, Ruby, C/C++, ...
* Support for multiple WASI components, in arbitrary languages to combine, e.g. JS + Rust.
* Better sandboxing for I/O.
  * File-IO is now limited to R/O of an explicitly specified root path `--wasm-root-dir`.
* Safe Rust code. Consistent TLS.
* We would like this to become the de-facto path to extend TrailBase (as opposed
  to using it as a framework), while providing a lot of flexibility in terms of
  languages, ...
* This may also open up the path to using a more mainstream copy-left license.
* We may support custom efficient SQLite extensions w/o accidental state sharing.
* Fix interval and callback timers are now working reliably.

*/}

## Regressions

While WASM can be handily faster than V8, JS in particular loads and runs
significantly slower when compared to a highly specialized and optimized
runtime like V8.
What may feel like a step backward from a JS-centric point of view also provides
opportunity to optimize individual handlers in different languages based on
specific needs.

In practice, JS is probably one of the least-efficient compile-to-WASM
languages. Instead of emitting immediate WebAssembly, current build flows
bundle an interpreter like SpiderMonkey to work around JS' dynamic nature, e.g.
`eval('console.log()')`[^3].

In practice, using `weval` execution is about as fast as Goja - PocketBase's JS
interpreter - and about 40x slower than V8.
On the other hand, Rust compiled to WASM is about 4x faster than V8 with more
predictable latency and lower resource footprint.
A benefit of the new integration is that different endpoints can be implemented
in different languages.

{/*
* A separate build step is needed to translate JS/TS to WASM, as opposed to
  lazily loading and just-in-time compiling a script.
* The resulting bundle, including the interpreter, tends to be large resulting
  in non-trivial initial load time in the order of seconds. Builds are being
  cached, restarts will thus be siginificantly faster.
*/}

## Migration

The first difference you'll encounter is the need for a build-step: JS/TS -> WASM[^5].
For now, we recommend to copy the template in `examples/wasm-guest-ts` or
`examples/wasm-guest-ts`, dependning on whether you prefer TypeScript or
JavaScript respectively.
You can then simply run `pnpm install && pnpm build` to build the WASM component.

Moreover, due to the new rigorous state-isolation and short-live nature of runtime instances, the
APIs for registering handlers had to change.
Previously we were heavily relying on global state for routing.
To avoid re-initialization on every request and for better symmetry with future
guest languages that may not support support eager initialization, we're now
relying on module exports for registering custom HTTP and Job handlers.

Before:

```ts
addRoute(
  "GET",
  "/test",
  stringHandler(async (req: StringRequestType) => {
    const uri: ParsedPath = parsePath(req.uri);

    const table = uri.query.get("table");
    if (table) {
      const rows = await query(`SELECT COUNT(*) FROM "${table}"`, []);
      return `entries: ${rows[0][0]}`;
    }

    return `test: ${req.uri}`;
  }
```

After:

```ts
export default defineConfig({
  httpHandlers: [
    HttpHandler.get("/test", (req: Request) : string => {
      const table = uri.getQueryParam("table");
      if (table) {
        const rows = await query(`SELECT COUNT(*) FROM "${table}"`, []);
        return `entries: ${rows[0][0]}`;
      }

      return `test: ${req.url()}`;
    },
  ],
});
```

## Next-Steps

First and foremost, we'd like to hear from you üôè.

Once the new runtime integration has seen some mileage and unforeseen surprises
are worked out, we'd like to sunset V8 expediently.
This will provide immediate benefits in terms of portability, security,
build-times and binary sizes.

From that point on we plan to invest heavily into making the integration
best-in-class. Something we were hesitant to do with the previous integration
due to all of its rough edges and unstable APIs. We'd like to introduce support
for more guest languages, making TrailBase easier to extend for a wider range
of developers developers and use-cases. If you think there's any language that
would be particularly valuable, e.g. due to its ecosystem, let us know.

When it becomes available, we'd also like to transparently upgrade the WASM
runtime to WASIp3, which will be the next standard making asynchronous
interactions between host and guest more of a first-class citizen.

---

[^1]:
    GLIBC static binaries aren't really static.

[^2]:
    As system to express cross-component interfaces for WASM in a
    language-agnostic manner. It's like gRPC but FFIi, i.e. no I/O
    thus allowing both asynchronous and synchronous interactions.

[^3]:
    That said, bundling the interpreter with static input unlocks some
    optimizations, e.g.
    [Futamura projection using weval](https://github.com/bytecodealliance/weval).

[^4]:
    For state sharing between requests you'll need should rely on SQLite or
    KVStore. Note that even with long-lived V8 isolates that was already the case,
    since state was only shared coincidentally within the same isolate, i.e.
    subsequent requests may or may not be able to see that state.

[^5]:
    A long-standing feature request for us has been to support hot-restart when
    components change. We're still planning to get there. A separate watcher
    process would re-build the WASM component and signal the `trail` binary to
    reload the WASM component.
